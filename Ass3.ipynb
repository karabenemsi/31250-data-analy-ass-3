{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import preprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Limited Sample: 2000\n",
      "Remove Field_info2 with variance of 0.0013437892283028393\nRemove Field_info4 with variance of 0.07113917319019872\nRemove Personal_info1 with variance of 0.0044842240940289975\nRemove Personal_info4 with variance of 0.0005002501250625312\nRemove Property_info1 with variance of 0.12158932319012358\nRemove Property_info2 with variance of 0.0\nRemove Geographic_info4 with variance of 0.02392337309796038\nDataFrame shape after feature selection:(1999, 25)\nDataFrame shape after outlier removal:(1832, 25)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train_target, train_data, test_data, train_df, test_df = preprocess.preprocess(\n",
    "    \"TrainingSet.csv\", 'TestSet.csv', limit=2000, remove_low_variance=True, remove_outliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Trainset has 378 times 1\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "X_g_train, X_g_test, y_g_train, y_g_test = train_test_split(train_data, train_target, test_size=0.30)\n",
    "print(f'Trainset has {train_target.sum()} times 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init some variables for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "result_predict = dict()\n",
    "test_predict = dict()\n",
    "\n",
    "def kFoldModel(model, X, y):\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    for train_idx, test_idx, in cv.split(X, y):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "        # Use SMOTE to oversample the dataset for better training accuracy\n",
    "        sm = SMOTE()\n",
    "        X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "        # Fit and predict\n",
    "        model.fit(X_train_oversampled, y_train_oversampled)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print(f'auc: {roc_auc_score(y_test, y_pred)}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "### Use Random Forest with found parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Start Random Forest\n",
      "auc: 0.7150479291011032\n",
      "auc: 0.6984536082474228\n",
      "auc: 0.7888406583468982\n",
      "auc: 0.6710652920962199\n",
      "auc: 0.7532183908045977\n0.9344985875706214\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Start Random Forest')\n",
    "model = RandomForestClassifier(n_estimators=128, criterion='entropy', n_jobs=-1)\n",
    "model = kFoldModel(model, train_data, train_target)\n",
    "y_predict = model.predict(X_g_test)\n",
    "auc_score = roc_auc_score(y_g_test, y_predict)\n",
    "print(auc_score)\n",
    "\n",
    "result_predict['RandomForest'] = np.array(model.predict(test_data))\n",
    "test_predict['RandomForest'] = np.array(model.predict(X_g_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest neighbour\n",
    "### Use k-nearest neighbour with found parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Start k-nearest neighbour\nauc: 0.7065699041417977\n",
      "auc: 0.7191852052812444\nauc: 0.6977301501175619\n",
      "auc: 0.6907903780068729\nauc: 0.670344827586207\n",
      "0.7327565913370998\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Start k-nearest neighbour')\n",
    "model = KNeighborsClassifier(n_neighbors=20, weights='uniform', n_jobs=-1)\n",
    "model = kFoldModel(model, train_data, train_target)\n",
    "y_predict = model.predict(X_g_test)\n",
    "auc_score = roc_auc_score(y_g_test, y_predict)\n",
    "print(auc_score)\n",
    "\n",
    "result_predict['KNeighbors'] = np.array(model.predict(test_data))\n",
    "test_predict['KNeighbors'] = np.array(model.predict(X_g_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "### Use SVM with found parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "SVM\n",
      "auc: 0.7122671369144511\n",
      "auc: 0.71545487429915\n",
      "auc: 0.7225764152649665\n",
      "auc: 0.6510652920962199\n",
      "auc: 0.6489655172413793\n0.6907172002510985\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('SVM')\n",
    "model = SVC(gamma='auto', kernel='rbf')\n",
    "model = kFoldModel(model, train_data, train_target)\n",
    "y_predict = model.predict(X_g_test)\n",
    "auc_score = roc_auc_score(y_g_test, y_predict)\n",
    "print(auc_score)\n",
    "\n",
    "result_predict['SVM'] = np.array(model.predict(test_data))\n",
    "test_predict['SVM'] = np.array(model.predict(X_g_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Linear SVM\nauc: 0.7604223186833062\nauc: 0.7080846446011937\nauc: 0.747852233676976\nauc: 0.6453608247422681\nauc: 0.694712643678161\n0.7016046767106089\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## Linear SVM\n",
    "print('Linear SVM')\n",
    "model = LinearSVC(random_state=0, tol=1e-5, dual=True, loss='squared_hinge')\n",
    "model = kFoldModel(model, train_data, train_target)\n",
    "y_predict = model.predict(X_g_test)\n",
    "auc_score = roc_auc_score(y_g_test, y_predict)\n",
    "print(auc_score)\n",
    "\n",
    "result_predict['LinearSVM'] = np.array(model.predict(test_data))\n",
    "test_predict['LinearSVM'] = np.array(model.predict(X_g_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "### Use neural network with found parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Start MLPClassifier\n",
      "auc: 0.7722011213601013\n",
      "auc: 0.6972327726532825\n",
      "auc: 0.7810408753843372\n",
      "auc: 0.7012371134020619\n",
      "auc: 0.7126436781609194\n0.7771892655367231\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Start MLPClassifier')\n",
    "model = MLPClassifier(solver='adam', alpha=0.0001, learning_rate_init=0.001,\n",
    "                      hidden_layer_sizes=(24, 23, 22), max_iter=1000)\n",
    "model = kFoldModel(model, train_data, train_target)\n",
    "y_predict = model.predict(X_g_test)\n",
    "auc_score = roc_auc_score(y_g_test, y_predict)\n",
    "print(auc_score)\n",
    "\n",
    "result_predict['mlpNetwork'] = np.array(model.predict(test_data))\n",
    "test_predict['mlpNetwork'] = np.array(model.predict(X_g_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do stuff with unsure rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0 times 0 on TrainTest\n9 times 1 on TrainTest\n4898 times 2 on TrainTest\n8466 times 3 on TrainTest\n9327 times 4 on TrainTest\n3376 times 5 on TrainTest\n87.05322902285627% Unsure on TrainSet\n/n Test:\n212 times 0 on TrainTest\n60 times 1 on TrainTest\n54 times 2 on TrainTest\n69 times 3 on TrainTest\n77 times 4 on TrainTest\n78 times 5 on TrainTest\n47.27272727272727% Unsure on TrainSet\nAUC: 0.8007297551789078\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result_predict)\n",
    "result_df['Sum'] = result_df.sum(axis=1)\n",
    "final = []\n",
    "width = len(result_df.keys()) - 1\n",
    "count = []\n",
    "# init counter\n",
    "for i in range(0,width+1):\n",
    "    count.append(0)\n",
    "for row in result_df['Sum']:\n",
    "    if 0 < row < width:\n",
    "        final.append(1 if row > ((width / 2)+1) else 0)\n",
    "        count[row] += 1\n",
    "    else:\n",
    "        count[row] += 1\n",
    "        final.append(0 if row == 0 else 1)\n",
    "result_df['Final'] = final\n",
    "for i in range(0,width+1):\n",
    "    print(str(count[i]) + ' times ' + str(i) + ' on TrainTest')\n",
    "print(str(sum(count[1:-1]) / len(result_df) * 100) + '% Unsure on TrainSet')\n",
    "\n",
    "print('/n Test:')\n",
    "# Do it for test to\n",
    "t_df = pd.DataFrame(test_predict)\n",
    "t_df['Sum'] = t_df.sum(axis=1)\n",
    "final = []\n",
    "width = len(t_df.keys()) - 1\n",
    "count = []\n",
    "# init counter\n",
    "for i in range(0,width+1):\n",
    "    count.append(0)\n",
    "for row in t_df['Sum']:\n",
    "    if 0 < row < width:\n",
    "        final.append(1 if row > ((width / 2)+1) else 0)\n",
    "        count[row] += 1\n",
    "    else:\n",
    "        count[row] += 1\n",
    "        final.append(0 if row == 0 else 1)\n",
    "t_df['Final'] = final\n",
    "for i in range(0,width+1):\n",
    "    print(str(count[i]) + ' times ' + str(i) + ' on TrainTest')\n",
    "print(str(sum(count[1:-1]) / len(t_df) * 100) + '% Unsure on TrainSet')\n",
    "print(f'AUC: {roc_auc_score(y_g_test, list(t_df[\"Final\"]))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Result to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_df['QuoteConversion_Flag'] = pd.Series(result_df['Final'], index=test_df.index)\n",
    "\n",
    "todrop = []\n",
    "for col in test_df.columns:\n",
    "    if col not in ['Quote_ID', 'QuoteConversion_Flag']:\n",
    "        todrop.append(col)\n",
    "test_df.drop(columns=todrop, inplace=True)\n",
    "test_df.to_csv('Kaggle_Submission.csv', index=False)\n",
    "print('Written to file')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}