{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import preprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_target, train_data, test_data, train_df, test_df = preprocess.preprocess(\n",
    "    \"TrainingSet.csv\", 'TestSet.csv', limit=None, remove_low_variance=True, remove_outliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_g_train, X_g_test, y_g_train, y_g_test = train_test_split(train_data, train_target, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init some variables for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "result_predict = dict()\n",
    "test_predict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best parameters for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=162, criterion='entropy',n_jobs=-1)\n",
    "for train_idx, test_idx, in cv.split(train_data, train_target):\n",
    "    X_train, y_train = train_data[train_idx], train_target[train_idx]\n",
    "    X_test, y_test = train_data[test_idx], train_target[test_idx]\n",
    "\n",
    "    # Use SMOTE to oversample the dataset for better training accuracy\n",
    "    sm = SMOTE()\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    parameters = {'n_estimators':range(100,200), 'criterion':('entropy','gini')}\n",
    "    gridSearch = GridSearchCV(model, parameters, cv=5)\n",
    "    gridSearch.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "    print(gridSearch.cv_results_['params'][gridSearch.best_index_])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Random Forest with found parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=162, criterion='entropy',n_jobs=-1)\n",
    "for train_idx, test_idx, in cv.split(train_data, train_target):\n",
    "    X_train, y_train = train_data[train_idx], train_target[train_idx]\n",
    "    X_test, y_test = train_data[test_idx], train_target[test_idx]\n",
    "\n",
    "    # Use SMOTE to oversample the dataset for better training accuracy\n",
    "    sm = SMOTE()\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # Fit and predict\n",
    "    model.fit(X_train_oversampled, y_train_oversampled)  \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f'auc: {roc_auc_score(y_test, y_pred)}')\n",
    "\n",
    "y_predict = model.predict(X_g_test)\n",
    "\n",
    "print(roc_auc_score(y_g_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "result_predict['RandomForest'] = np.array(model.predict(test_data))\n",
    "test_predict['RandomForest'] = np.array(model.predict(y_g_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest neighbour\n",
    "### Find best parameters for  k-nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = KNeighborsClassifier()\n",
    "#parameters = {'n_neighbors':range(1,20), 'weights':('uniform', 'distance')}\n",
    "#gridSearch = GridSearchCV(model, parameters, cv=5)\n",
    "#gridSearch.fit(X_train, y_train)\n",
    "\n",
    "gridSearch.best_params_\n",
    "gridSearch.best_score_ \n",
    "gridSearch.cv_results_['params'][gridSearch.best_index_]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use k-nearest neighbour with found parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=20, weights='uniform', n_jobs=-1)\n",
    "for train_idx, test_idx, in cv.split(train_data, train_target):\n",
    "    X_train, y_train = train_data[train_idx], train_target[train_idx]\n",
    "    X_test, y_test = train_data[test_idx], train_target[test_idx]\n",
    "\n",
    "    # Use SMOTE to oversample the dataset for better training accuracy\n",
    "    sm = SMOTE()\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # Fit and predict\n",
    "    model.fit(X_train_oversampled, y_train_oversampled)  \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f'auc: {roc_auc_score(y_test, y_pred)}')\n",
    "\n",
    "y_predict = model.predict(X_g_test)\n",
    "\n",
    "print(roc_auc_score(y_g_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "result_predict['KNeighbors'] = np.array(model.predict(test_data))\n",
    "test_predict['KNeighbors'] = np.array(model.predict(y_g_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "### Find best parameters for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = KNeighborsClassifier()\n",
    "#parameters = {'n_neighbors':[1,20], 'weights':('uniform', 'distance')}\n",
    "#gridSearch = GridSearchCV(model, parameters, cv=5)\n",
    "#gridSearch.fit(X_train, y_train)\n",
    "\n",
    "#gridSearch.cv_results_['params'][gridSearch.best_index_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SVM with found parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighbors = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "#KNeighbors.fit(X_train, y_train)\n",
    "#y_predict = KNeighbors.predict(X_test)\n",
    "\n",
    "#print(roc_auc_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_predict['SVM'] = np.array(model.predict(test_data))\n",
    "#test_predict['SVM'] = np.array(model.predict(y_g_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "### Find best parameters for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(max_iter=500)\n",
    "parameters = {'solver': ('adam',),\n",
    "              'alpha': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "              'hidden_layer_sizes': [(6, 6), (7, 7), (8, 8), (9, 9), (10, 10),\n",
    "                                     #(11, 11), (12, 12), (13, 13), (14, 14), (15, 15), (16, 16), (17, 17), (18, 18),\n",
    "                                     #(19, 19), (20, 20), (21, 21), (22, 22), (23, 23), (24, 24), (25, 25), (26, 26),\n",
    "                                     #(27, 27), (28, 28), (29, 29), (30, 30), (31, 31), (32, 32), (33, 33), (34, 34),\n",
    "                                     #(35, 35), (36, 36), (37, 37), (38, 38), (39, 39), (40, 40), (41, 41), (42, 42),\n",
    "                                     #(43, 43), (44, 44), (45, 45), (46, 46), (47, 47), (48, 48), (49, 49), (50, 50),\n",
    "                                     #(51, 51), (52, 52), (53, 53), (54, 54), (55, 55), (56, 56), (57, 57), (58, 58),\n",
    "                                     #(59, 59), (60, 60), (61, 61), (62, 62), (63, 63), (64, 64), (65, 65), (66, 66),\n",
    "                                     #(67, 67), (68, 68), (69, 69), (70, 70), (71, 71), (72, 72), (73, 73), (74, 74),\n",
    "                                     #(75, 75), (76, 76), (77, 77), (78, 78), (79, 79), (80, 80), (81, 81), (82, 82),\n",
    "                                     #(83, 83), (84, 84), (85, 85), (86, 86), (87, 87), (88, 88), (89, 89), (90, 90),\n",
    "                                     #(91, 91), (92, 92), (93, 93), (94, 94), (95, 95), (96, 96), (97, 97), (98, 98),\n",
    "                                     #(99, 99), (100, 100), (1, 1, 1), (2, 2, 2), (3, 3, 3), (4, 4, 4), (5, 5, 5),\n",
    "                                     (6, 6, 6), (7, 7, 7), (8, 8, 8), (9, 9, 9), (10, 10, 10), (11, 11, 11),\n",
    "                                     (12, 12, 12), (13, 13, 13), (14, 14, 14), (15, 15, 15), (16, 16, 16), (17, 17, 17),\n",
    "                                     (18, 18, 18), (19, 19, 19), (20, 20, 20), (21, 21, 21), (22, 22, 22), (23, 23, 23),\n",
    "                                     (24, 24, 24), (25, 25, 25), (26, 26, 26), (27, 27, 27), (28, 28, 28), (29, 29, 29),\n",
    "                                     (30, 30, 30), (31, 31, 31), (32, 32, 32), (33, 33, 33), (34, 34, 34), (35, 35, 35),\n",
    "                                    # (36, 36, 36), (37, 37, 37), (38, 38, 38), (39, 39, 39), (40, 40, 40), (41, 41, 41),\n",
    "                                    # (42, 42, 42), (43, 43, 43), (44, 44, 44), (45, 45, 45), (46, 46, 46), (47, 47, 47),\n",
    "                                    # (48, 48, 48), (49, 49, 49), (50, 50, 50), (51, 51, 51), (52, 52, 52), (53, 53, 53),\n",
    "                                    # (54, 54, 54), (55, 55, 55), (56, 56, 56), (57, 57, 57), (58, 58, 58), (59, 59, 59),\n",
    "                                    #(60, 60, 60), (61, 61, 61), (62, 62, 62), (63, 63, 63), (64, 64, 64), (65, 65, 65),\n",
    "                                     (66, 66, 66), (67, 67, 67), (68, 68, 68), (69, 69, 69), (70, 70, 70), (71, 71, 71),\n",
    "                                     (72, 72, 72), (73, 73, 73), (74, 74, 74), (75, 75, 75), (76, 76, 76), (77, 77, 77),\n",
    "                                    # (78, 78, 78), (79, 79, 79), (80, 80, 80), (81, 81, 81), (82, 82, 82), (83, 83, 83),\n",
    "                                     #(84, 84, 84), (85, 85, 85), (86, 86, 86), (87, 87, 87), (88, 88, 88), (89, 89, 89),\n",
    "                                     #(90, 90, 90), (91, 91, 91), (92, 92, 92), (93, 93, 93), (94, 94, 94), (95, 95, 95),\n",
    "                                     #(96, 96, 96), (97, 97, 97), (98, 98, 98), (99, 99, 99), (100, 100, 100),\n",
    "                                     #(1, 1, 1, 1), (2, 2, 2, 2), (3, 3, 3, 3), (4, 4, 4, 4), (5, 5, 5, 5), (6, 6, 6, 6),\n",
    "                                     #(7, 7, 7, 7), (8, 8, 8, 8), (9, 9, 9, 9), (10, 10, 10, 10), (11, 11, 11, 11),\n",
    "                                     #(12, 12, 12, 12), (13, 13, 13, 13), (14, 14, 14, 14), (15, 15, 15, 15),\n",
    "                                     #(16, 16, 16, 16), (17, 17, 17, 17), (18, 18, 18, 18), (19, 19, 19, 19),\n",
    "                                     #(20, 20, 20, 20), (21, 21, 21, 21), (22, 22, 22, 22), (23, 23, 23, 23),\n",
    "                                     #(24, 24, 24, 24), (25, 25, 25, 25), (26, 26, 26, 26), (27, 27, 27, 27),\n",
    "                                     (28, 28, 28, 28), (29, 29, 29, 29), (30, 30, 30, 30), (31, 31, 31, 31),\n",
    "                                     (32, 32, 32, 32), (33, 33, 33, 33), (34, 34, 34, 34), (35, 35, 35, 35),\n",
    "                                     (36, 36, 36, 36), (37, 37, 37, 37), (38, 38, 38, 38), (39, 39, 39, 39),\n",
    "                                     (40, 40, 40, 40), (41, 41, 41, 41), (42, 42, 42, 42), (43, 43, 43, 43),\n",
    "                                     (44, 44, 44, 44), (45, 45, 45, 45), (46, 46, 46, 46), (47, 47, 47, 47),\n",
    "                                     (48, 48, 48, 48), (49, 49, 49, 49), (50, 50, 50, 50), (51, 51, 51, 51),\n",
    "                                     (52, 52, 52, 52), (53, 53, 53, 53), (54, 54, 54, 54), (55, 55, 55, 55),\n",
    "                                     (56, 56, 56, 56), (57, 57, 57, 57), (58, 58, 58, 58), (59, 59, 59, 59),\n",
    "                                     (60, 60, 60, 60), (61, 61, 61, 61), (62, 62, 62, 62), (63, 63, 63, 63),\n",
    "                                     (64, 64, 64, 64), (65, 65, 65, 65), (66, 66, 66, 66), (67, 67, 67, 67),\n",
    "                                     (68, 68, 68, 68), (69, 69, 69, 69), (70, 70, 70, 70), (71, 71, 71, 71),\n",
    "                                     (72, 72, 72, 72), (73, 73, 73, 73), (74, 74, 74, 74), (75, 75, 75, 75),\n",
    "                                     (76, 76, 76, 76), (77, 77, 77, 77), (78, 78, 78, 78), (79, 79, 79, 79),\n",
    "                                     (80, 80, 80, 80), (81, 81, 81, 81), (82, 82, 82, 82), (83, 83, 83, 83),\n",
    "                                     (84, 84, 84, 84), (85, 85, 85, 85), (86, 86, 86, 86), (87, 87, 87, 87),\n",
    "                                     (88, 88, 88, 88), (89, 89, 89, 89), (90, 90, 90, 90), (91, 91, 91, 91),\n",
    "                                     (92, 92, 92, 92), (93, 93, 93, 93), (94, 94, 94, 94), (95, 95, 95, 95),\n",
    "                                     (96, 96, 96, 96), (97, 97, 97, 97), (98, 98, 98, 98), (99, 99, 99, 99),\n",
    "                                     (100, 100, 100, 100)]\n",
    "              }\n",
    "gridSearch = GridSearchCV(model, parameters, cv=5)\n",
    "gridSearch.fit(X_train, y_train)\n",
    "\n",
    "gridSearch.cv_results_['params'][gridSearch.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = [2,3,4]\n",
    "#b= range(1,101)\n",
    "#for i in a:\n",
    "#    for j in b:\n",
    "#        print('(' + ((str(j) + ',') * i)[:-1] + '),' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use neural network with found parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "model = MLPClassifier(solver='adam', alpha=0.001, learning_rate_init=0.0001,\n",
    "                           hidden_layer_sizes=(25, 10,10), max_iter=1000)\n",
    "for train_idx, test_idx, in cv.split(train_data, train_target):\n",
    "    X_train, y_train = train_data[train_idx], train_target[train_idx]\n",
    "    X_test, y_test = train_data[test_idx], train_target[test_idx]\n",
    "\n",
    "    # Use SMOTE to oversample the dataset for better training accuracy\n",
    "    sm = SMOTE()\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # Fit and predict\n",
    "    model.fit(X_train_oversampled, y_train_oversampled)  \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f'auc: {roc_auc_score(y_test, y_pred)}')\n",
    "\n",
    "y_predict = model.predict(X_g_test)\n",
    "\n",
    "print(roc_auc_score(y_g_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "result_predict['mlpNetwork'] = np.array(model.predict(test_data))\n",
    "test_predict['mlpNetwork'] = np.array(model.predict(y_g_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do stuff with unsure rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result_predict)\n",
    "result_df['Sum'] = result_df.sum(axis=1)\n",
    "\n",
    "\n",
    "count = 0\n",
    "final = []\n",
    "width = len(result_df.keys())-1\n",
    "for row in result_df['Sum']:\n",
    "    if 0 < row < width:\n",
    "        #print(1 if row > (width/2) else 0)\n",
    "        final.append(1 if row > (width/2) else 0)\n",
    "        count+=1\n",
    "    else:\n",
    "        final.append(0 if row == 0 else 1)\n",
    "result_df['Final']=final\n",
    "print(str(count/len(result_df)*100) + '% Unsure')\n",
    "\n",
    "t_df = pd.DataFrame(result_predict)\n",
    "t_df['Sum'] = t_df.sum(axis=1)\n",
    "\n",
    "\n",
    "count = 0\n",
    "final = []\n",
    "width = len(t_df.keys())-1\n",
    "for row in t_df['Sum']:\n",
    "    if 0 < row < width:\n",
    "        #print(1 if row > (width/2) else 0)\n",
    "        final.append(1 if row > (width/2) else 0)\n",
    "        count+=1\n",
    "    else:\n",
    "        final.append(0 if row == 0 else 1)\n",
    "t_df['Final']=final\n",
    "print(str(count/len(t_df)*100) + '% Unsure')\n",
    "\n",
    "\n",
    "roc_auc_score(y_g_test,list(t_df['Final']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Result to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test_df['QuoteConversion_Flag'] = pd.Series(result_df['Final'], index=test_df.index)\n",
    "\n",
    "todrop=[]\n",
    "for col in test_df.columns:\n",
    "    if col not in ['Quote_ID','QuoteConversion_Flag']:\n",
    "        todrop.append(col)\n",
    "test_df.drop(columns=todrop, inplace=True)\n",
    "test_df.to_csv('Kaggle_Submission.csv', index=False)\n",
    "test_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
